{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a75bbf7b-af1a-4b4b-a272-310db3f051eb",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'clf__max_depth': 5, 'clf__n_estimators': 100}\n",
            "Best CV ROC AUC: 0.8700880276115385\n",
            "Accuracy: 0.8156424581005587\n",
            "Precision: 0.8\n",
            "Recall: 0.6956521739130435\n",
            "F1: 0.7441860465116279\n",
            "ROC AUC: 0.8480895915678524\n",
            "Confusion matrix:\n",
            " [[98 12]\n",
            " [21 48]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['titanic_model_7features.pkl']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Load cleaned training data\n",
        "df = pd.read_csv(\"Cleaned_Data.csv\")\n",
        "\n",
        "# 1) Feature engineering to create Title, FamilySize, IsAlone from cleaned data\n",
        "# - FamilySize and IsAlone exist in Cleaned_Data.csv, but we recompute to be robust\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['IsAlone'] = (df['FamilySize'] == 1)\n",
        "\n",
        "# Extract Title from Name and bucket to Miss/Mr/Mrs/Rare\n",
        "def extract_title(name):\n",
        "    m = re.search(r',\\s*([^\\.]+)\\.', str(name))\n",
        "    return m.group(1).strip() if m else 'Rare'\n",
        "\n",
        "def map_title_to_buckets(title):\n",
        "    if title in ['Mr']:\n",
        "        return 'Mr'\n",
        "    if title in ['Mrs', 'Mme', 'Lady', 'Countess']:\n",
        "        return 'Mrs'\n",
        "    if title in ['Miss', 'Mlle']:\n",
        "        return 'Miss'\n",
        "    return 'Rare'\n",
        "\n",
        "df['Title'] = df['Name'].apply(extract_title).apply(map_title_to_buckets)\n",
        "\n",
        "# 2) Select ONLY the 7 requested features for X, and Survived as y\n",
        "feature_cols = ['Sex', 'Pclass', 'Age', 'Fare', 'Title', 'FamilySize', 'IsAlone']\n",
        "X = df[feature_cols].copy()\n",
        "y = df['Survived'].astype(int)\n",
        "\n",
        "# 3) Train/test split (same seed and stratify as your original)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4) Preprocessing: impute + scale numerics; OHE for Title; pass IsAlone as categorical/bool\n",
        "num_features = ['Sex', 'Pclass', 'Age', 'Fare', 'FamilySize']\n",
        "cat_features = ['Title', 'IsAlone']  # Title is object; IsAlone is bool\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipe, num_features),\n",
        "    ('cat', cat_pipe, cat_features)\n",
        "])\n",
        "\n",
        "# 5) Build pipeline and tune RandomForest on ROC AUC\n",
        "pipe_rf = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'clf__n_estimators': [100, 200],\n",
        "    'clf__max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(pipe_rf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"Best CV ROC AUC:\", gs.best_score_)\n",
        "\n",
        "# 6) Evaluate on held-out test set\n",
        "best_model = gs.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 7) Save the retrained model\n",
        "joblib.dump(best_model, 'titanic_model_7features.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
